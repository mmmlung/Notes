# Markdown Cheat Sheet

# Header level 0
## Header level 1
### _Header level 2 italic_

_italic_ versus **bold**

**__italic_and_bold__**

Ein Inline-Link [Hier gehts zu Hackernews ](https://news.ycombinator.com/)

Eine fetter Inline-Link [**Inspierende Mathematikvideos gibt es hier**](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)

Ein Referenz-Link [Hier lernst du Neuronale Netze][Neuronale Netze]

[Neuronale Netze]: https://www.coursera.org/learn/neural-networks-deep-learning

Ein Inline-Image-Link ![HI](https://www.neuraldesigner.com/images/deep_neural_network.png)

Ein Referenz-Image Link ![HI][second_neural]

[second_neural]: http://www.mdpi.com/water/water-10-00004/article_deploy/html/images/water-10-00004-g007.png

Ein Blockzitat: 
> "In god we trust, all others bring data !" 
>
> W. Edwards Deming

Eine ungeordnete Liste:
* Perzeptron
* Aktivierungsfunktion
 * Linear  
   f(x) = ax+b (soft break)
 * tanh (_tangens hyperbolicus_)

   tanh(x) = sinh(x)/cosh(x) (hard break)
 * relu (_rectified linear unit_)

   relux(x) = max(0, ax+b)
* Kostenfunktion
* Forward propagation
* backward propagation

Eine nummerierte Liste:

1. Sigmoid Funktion
2. Relu Funktion
3. Kettenregel

Eine Abschnitt

Proofs  footprints of logic  
show how, where one truth leads  
another follows



